{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Redundant Packages\n",
    "# ! pip install selectivesearch\n",
    "!pip install scikit-image==0.14.5\n",
    "# ! pip install numpy==1.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from __future__ import print_function\n",
    "\n",
    "from config import *\n",
    "from utils import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "class_names=[]\n",
    "batch_size = 0\n",
    "input_shape=(0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "\n",
    "    global batch_size\n",
    "    batch_size = batch_size_train\n",
    "    logging.debug('batch_size {}'.format(batch_size))\n",
    "\n",
    "    global class_names\n",
    "    class_names = sorted(get_subdir_list(dataset_train_path))\n",
    "    logging.debug('class_names {}'.format(class_names))\n",
    "\n",
    "    global input_shape\n",
    "    input_shape = (img_width, img_height, img_channel)\n",
    "    logging.debug('input_shape {}'.format(input_shape))\n",
    "\n",
    "\n",
    "    if not os.path.exists(output_path_name):\n",
    "        os.makedirs(output_path_name)\n",
    "\n",
    "    if not os.path.exists(logs_path_name):\n",
    "        os.makedirs(logs_path_name)\n",
    "\n",
    "    if not os.path.exists(btl_path):\n",
    "        os.makedirs(btl_path)\n",
    "\n",
    "    if not os.path.exists(btl_train_path):\n",
    "        os.makedirs(btl_train_path)\n",
    "\n",
    "    if not os.path.exists(btl_val_path):\n",
    "        os.makedirs(btl_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottleneck():\n",
    "    logging.debug('class_names {}'.format(class_names))\n",
    "    logging.debug('batch_size {}'.format(batch_size))\n",
    "    logging.debug('epochs {}'.format(epochs))\n",
    "    logging.debug('input_shape {}'.format(input_shape))\n",
    "\n",
    "\n",
    "    ## Build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    #model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "\n",
    "    for train_val in ['train', 'validation']:\n",
    "\n",
    "        with open('bottleneck/btl_' + train_val + '.txt', 'w') as f_image:\n",
    "            for class_name in class_names:\n",
    "                dataset_train_class_path = os.path.join(dataset_path, train_val, class_name)\n",
    "                logging.debug('dataset_train_class_path {}'.format(dataset_train_class_path))\n",
    "\n",
    "                images_list = []\n",
    "                images_name_list = []\n",
    "\n",
    "                images_path_name = sorted(glob.glob(dataset_train_class_path + '/*.jpg'))\n",
    "                logging.debug('images_path_name {}'.format(len(images_path_name)))\n",
    "\n",
    "                for index, image in enumerate(images_path_name):\n",
    "                    # logging.debug('image {}'.format(image))\n",
    "\n",
    "                    img = Image.open(image)\n",
    "\n",
    "                    img = preprocess_image(img)\n",
    "\n",
    "                    current_batch_size = len(images_list)\n",
    "                    # logging.debug('current_batch_size {}'.format(current_batch_size))\n",
    "\n",
    "                    images_list.append(img)\n",
    "\n",
    "                    image_name = image.split('/')[-1].split('.jpg')[0]\n",
    "                    images_name_list.append(image)\n",
    "                    images_list_arr = np.array(images_list)\n",
    "\n",
    "                    # TODO: Skipping n last images of a class which do not sum up to batch_size\n",
    "                    if (current_batch_size < batch_size-1):\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    X = images_list_arr\n",
    "\n",
    "                    bottleneck_features_train_class = model.predict(X, batch_size)\n",
    "                    # bottleneck_features_train_class = model.predict(X, nb_train_class_samples // batch_size)\n",
    "\n",
    "\n",
    "                    ## Save bottleneck file\n",
    "                    btl_save_file_name = btl_path + train_val + '/btl_' + train_val + '_' + class_name + '.' + str(index).zfill(7) + '.npy'\n",
    "                    logging.info('btl_save_file_name {}'.format(btl_save_file_name))\n",
    "                    np.save(open(btl_save_file_name, 'wb'), bottleneck_features_train_class)\n",
    "                    for name in images_name_list:\n",
    "                        f_image.write(str(name) + '\\n')\n",
    "\n",
    "                    images_list = []\n",
    "                    images_name_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "\n",
    "    ## Build network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    #model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "\n",
    "\n",
    "    # Get sorted bottleneck file names in a list\n",
    "    btl_train_names = sorted(glob.glob(btl_train_path + '/*.npy'))\n",
    "    btl_val_names = sorted(glob.glob(btl_val_path + '/*.npy'))\n",
    "\n",
    "\n",
    "\n",
    "    ## Train Labels\n",
    "    btl_train_list = []\n",
    "    train_labels_class = []\n",
    "    train_labels_iou = []\n",
    "\n",
    "    # Get list of image IoU values\n",
    "    with open('bottleneck/btl_train.txt') as f_btl_train:\n",
    "        btl_train_list = f_btl_train.readlines()\n",
    "        # logging.debug('btl_train_list {}'.format(btl_train_list))\n",
    "    for btl_train_image in btl_train_list:\n",
    "        train_labels_class.append(btl_train_image.split('/')[2])\n",
    "        iou_value = np.round(np.float( btl_train_image.split('_')[-1].split('.jpg')[0] ), 2)\n",
    "        train_labels_iou.append(iou_value)\n",
    "        # logging.debug('val {}'.format(val))\n",
    "\n",
    "    # logging.debug('class_names {}'.format(class_names))\n",
    "    # logging.debug('train_labels_class {}'.format(train_labels_class))\n",
    "    train_labels_class_int = []\n",
    "    for index, class_name in enumerate(train_labels_class):\n",
    "        train_labels_class_int.append(class_names.index(class_name))\n",
    "    train_labels_class = train_labels_class_int\n",
    "    # logging.debug('train_labels_class {}'.format(train_labels_class))\n",
    "\n",
    "    train_labels_class = np.array(train_labels_class)\n",
    "    train_labels_iou = np.array(train_labels_iou)\n",
    "    logging.debug('train_labels_iou {}'.format(train_labels_iou))\n",
    "    logging.debug('train_labels_iou {}'.format(type(train_labels_iou)))\n",
    "    logging.debug('train_labels_class {}'.format(type(train_labels_class)))\n",
    "    logging.debug('train_labels_class {}'.format((train_labels_class.shape)))\n",
    "\n",
    "    # Load bottleneck files to create train set\n",
    "    train_data = []\n",
    "    for index, btl_name in enumerate(btl_train_names):\n",
    "        temp = np.load(open(btl_name))\n",
    "        train_data.append(temp)\n",
    "\n",
    "    train_data = np.array(train_data)\n",
    "    n1, n2, w, h, c = train_data.shape\n",
    "    logging.info('train_data {}'.format(train_data.shape))\n",
    "    train_data_ = train_data\n",
    "    train_data = np.reshape(train_data_, (n1*n2, w, h, c))\n",
    "    logging.info('train_data {}'.format(train_data.shape))\n",
    "\n",
    "\n",
    "\n",
    "    ## Validation Labels\n",
    "    btl_val_list = []\n",
    "    val_labels_class = []\n",
    "    val_labels_iou = []\n",
    "\n",
    "    # Get list of image IoU values\n",
    "    with open('bottleneck/btl_validation.txt') as f_btl_val:\n",
    "        btl_val_list = f_btl_val.readlines()\n",
    "        # logging.debug('btl_val_list {}'.format(btl_val_list))\n",
    "    for btl_val_image in btl_val_list:\n",
    "        val_labels_class.append(btl_val_image.split('/')[2])\n",
    "        val = np.round(np.float( btl_val_image.split('_')[-1].split('.jpg')[0] ), 2)\n",
    "        val_labels_iou.append(val)\n",
    "        # logging.debug('val {}'.format(val))\n",
    "\n",
    "    # logging.debug('val_labels_class {}'.format(val_labels_class))\n",
    "    val_labels_class_int = []\n",
    "    for index, class_name in enumerate(val_labels_class):\n",
    "        val_labels_class_int.append(class_names.index(class_name))\n",
    "    val_labels_class = val_labels_class_int\n",
    "    # logging.debug('val_labels_class {}'.format(val_labels_class))\n",
    "\n",
    "    val_labels_class = np.array(val_labels_class)\n",
    "    # logging.debug('val_labels_class {}'.format(val_labels_class))\n",
    "    val_labels_iou = np.array(val_labels_iou)\n",
    "    # logging.debug('val_labels_iou {}'.format(val_labels_iou))\n",
    "    logging.debug('val_labels_iou {}'.format(type(val_labels_iou)))\n",
    "    logging.debug('val_labels_class {}'.format(type(val_labels_class)))\n",
    "    logging.debug('val_labels_class {}'.format(val_labels_class.shape))\n",
    "\n",
    "    # Load bottleneck files to create validation set\n",
    "    val_data = []\n",
    "    for index, btl_name in enumerate(btl_val_names):\n",
    "        temp = np.load(open(btl_name,'rb'))\n",
    "        val_data.append(temp)\n",
    "\n",
    "    val_data = np.array(val_data)\n",
    "    n1, n2, w, h, c = val_data.shape\n",
    "    logging.info('val_data {}'.format(val_data.shape))\n",
    "    val_data_ = val_data\n",
    "    val_data = np.reshape(val_data_, (n1*n2, w, h, c))\n",
    "    logging.info('val_data {}'.format(val_data.shape))\n",
    "\n",
    "\n",
    "\n",
    "    ## Register Callbacks\n",
    "    filename = 'output/model_train.csv'\n",
    "    csv_log = CSVLogger(filename, separator=' ', append=False)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss', patience=early_stopping_patience, verbose=1, mode='min')\n",
    "\n",
    "    #filepath = \"output/best-weights-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "    filepath = \"output/best-weights-{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1,\n",
    "        save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=logs_path_name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "    callbacks_list = [csv_log, early_stopping, checkpoint, tensorboard]\n",
    "    logging.info('callbacks_list {}'.format(callbacks_list))\n",
    "\n",
    "\n",
    "    ## Generate weights based on images count for each class\n",
    "    class_weight_val = class_weight.compute_class_weight('balanced', np.unique(train_labels_class), train_labels_class)\n",
    "    logging.debug('class_weight_val {}'.format(class_weight_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    input_shape_btl_layer = train_data.shape[1:]\n",
    "    logging.debug('input_shape_btl_layer {}'.format(input_shape_btl_layer))\n",
    "    #model = create_model(is_input_bottleneck=True, is_load_weights=False, input_shape, optimizer, learn_rate, decay, momentum, activation, dropout_rate)\n",
    "    model = create_model(True, False, input_shape_btl_layer, len(class_names), optimizer, learn_rate, decay, momentum, activation, dropout_rate)\n",
    "\n",
    "    logging.info('train_labels_iou {}'.format(train_labels_iou.shape))\n",
    "    logging.info('train_labels_class {}'.format(train_labels_class.shape))\n",
    "    logging.info('train_data {}'.format(train_data.shape))\n",
    "\n",
    "\n",
    "    logging.info('val_labels_iou {}'.format(val_labels_iou.shape))\n",
    "    logging.info('val_labels_class {}'.format(val_labels_class.shape))\n",
    "    logging.info('val_data {}'.format(val_data.shape))\n",
    "\n",
    "    # TODO: class_weight_val wrong\n",
    "    model.fit(train_data, [train_labels_class, train_labels_iou],\n",
    "            class_weight=[class_weight_val, class_weight_val],                                      # dictionary mapping classes to a weight value, used for scaling the loss function (during training only).\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(val_data, [val_labels_class, val_labels_iou]),\n",
    "            callbacks=callbacks_list)\n",
    "\n",
    "    # TODO: These are not the best weights\n",
    "    model.save_weights(top_model_weights_path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Input, Output Data\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p27]",
   "language": "python",
   "name": "conda-env-tensorflow_p27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
